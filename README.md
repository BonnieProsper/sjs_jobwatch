# SJS JobWatch

**Monitor and track changes in the SJS New Zealand job board with automated email alerts.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ What Does This Do?

SJS JobWatch automatically:
- **Scrapes** job listings from the SJS New Zealand public service job board
- **Tracks** changes over time (new jobs, removed jobs, modified postings)
- **Sends** email alerts when relevant changes occur
- **Filters** by region, category, and change severity
- **Stores** historical snapshots for analysis

**Perfect for job seekers** who want to stay on top of new opportunities without manually checking the site every day.

---

## âœ¨ Features

### Core Functionality
- âœ… **Automated Scraping**: Fetch job listings from SJS with configurable filters
- âœ… **Change Detection**: Identify new, removed, and modified job postings
- âœ… **Email Alerts**: Beautiful HTML emails with change summaries
- âœ… **Flexible Filters**: Region, category, keyword search support
- âœ… **Historical Tracking**: Keep snapshots of past job boards
- âœ… **CLI Interface**: Easy-to-use command-line tools

### Technical Highlights
- ğŸ—ï¸ **Clean Architecture**: Separation of concerns (scraping â†’ storage â†’ diffing â†’ alerts)
- ğŸ”’ **Type Safe**: Full type hints with Pydantic models
- ğŸ“Š **Rich Output**: Beautiful terminal tables with the `rich` library
- ğŸ§ª **Testable**: Pure functions, dependency injection, no global state
- ğŸ“ **Well Documented**: Comprehensive docstrings and examples

---

## ğŸ“¦ Installation

### Requirements
- Python 3.10 or higher
- Gmail account (for sending email alerts)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/yourusername/sjs-jobwatch.git
cd sjs-jobwatch

# Install with pip
pip install -e .

# Or install with optional dev dependencies
pip install -e ".[dev]"
```

### Verify Installation

```bash
sjs-jobwatch --help
```

---

## ğŸš€ Quick Start

### 1. Scrape Your First Snapshot

```bash
# Scrape all jobs
sjs-jobwatch scrape

# Or filter by region
sjs-jobwatch scrape --region Auckland

# Or filter by category
sjs-jobwatch scrape --category ICT

# Search with keyword
sjs-jobwatch scrape --keyword "data analyst"
```

### 2. View Job Changes

After running a second scrape, view the differences:

```bash
# Compare latest snapshot with previous one
sjs-jobwatch diff

# Compare with snapshot from 2 scrapes ago
sjs-jobwatch diff --since 2

# View as plain text instead of table
sjs-jobwatch diff --format text
```

### 3. Set Up Email Alerts

```bash
# Add your email subscription
sjs-jobwatch alerts add your.email@example.com \
    --region Auckland \
    --category ICT \
    --frequency daily \
    --hour 9

# Test the alert (dry run)
sjs-jobwatch alerts test your.email@example.com --dry-run

# View all subscriptions
sjs-jobwatch alerts list
```

### 4. Run the Alert Service

```bash
# Run once and exit
sjs-jobwatch run --once

# Run continuously (checks hourly)
sjs-jobwatch run

# Dry run (no emails sent)
sjs-jobwatch run --dry-run
```

---

## ğŸ”§ Configuration

### Email Setup (Required for Alerts)

SJS JobWatch uses Gmail SMTP to send emails. You'll need to create an **App Password**:

1. Go to [Google Account Settings](https://myaccount.google.com/)
2. Security â†’ 2-Step Verification â†’ App passwords
3. Generate a new app password
4. Set environment variables:

```bash
export GMAIL_ADDRESS="your.email@gmail.com"
export GMAIL_APP_PASSWORD="xxxx xxxx xxxx xxxx"
```

**On Windows:**
```powershell
$env:GMAIL_ADDRESS="your.email@gmail.com"
$env:GMAIL_APP_PASSWORD="xxxx xxxx xxxx xxxx"
```

**Persistent Setup (Linux/Mac):**
```bash
# Add to ~/.bashrc or ~/.zshrc
echo 'export GMAIL_ADDRESS="your.email@gmail.com"' >> ~/.bashrc
echo 'export GMAIL_APP_PASSWORD="xxxx xxxx xxxx xxxx"' >> ~/.bashrc
source ~/.bashrc
```

### Advanced Configuration

Edit `src/sjs_jobwatch/core/config.py` to customize:
- Request delays and timeouts
- Snapshot retention policies
- Email formatting
- Logging levels

---

## ğŸ“š CLI Reference

### Scraping

```bash
# Basic scrape
sjs-jobwatch scrape

# With filters
sjs-jobwatch scrape --region Wellington --category "Policy"

# With keyword search
sjs-jobwatch scrape --keyword "senior developer"
```

**Available Regions:**
`All`, `Auckland`, `Wellington`, `Canterbury`, `Bay of Plenty`, `Waikato`, `Otago`, `Hawke's Bay`, `Manawatu-Wanganui`, `Northland`, `Taranaki`, `Nelson`, `Marlborough`, `Southland`, `Gisborne`, `Tasman`, `West Coast`, `Overseas`

**Available Categories:**
`All`, `ICT`, `Allied Health`, `Corporate`, `Education`, `Engineering`, `Facilities`, `Finance & Accounting`, `Health`, `Human Resources`, `Legal`, `Management`, `Operations`, `Planning`, `Policy`, `Science`, `Social Services`, `Trades & Services`, `Other`

### Viewing Changes

```bash
# Show differences from latest snapshot
sjs-jobwatch diff

# Compare with older snapshots
sjs-jobwatch diff --since 3

# Plain text output
sjs-jobwatch diff --format text
```

### Managing Snapshots

```bash
# List recent snapshots
sjs-jobwatch list

# List more snapshots
sjs-jobwatch list --limit 50

# Export latest snapshot
sjs-jobwatch export csv jobs.csv
sjs-jobwatch export json jobs.json

# Export older snapshot
sjs-jobwatch export csv jobs-old.csv --snapshot 5
```

### Managing Alert Subscriptions

```bash
# Add subscription
sjs-jobwatch alerts add email@example.com \
    --region Auckland \
    --category ICT \
    --frequency daily \
    --hour 9 \
    --severity medium

# List subscriptions
sjs-jobwatch alerts list

# Remove subscription
sjs-jobwatch alerts remove email@example.com

# Test alert
sjs-jobwatch alerts test email@example.com
sjs-jobwatch alerts test email@example.com --dry-run
```

**Alert Options:**
- `--frequency`: `daily` or `weekly`
- `--hour`: 0-23 (UTC time)
- `--severity`: `low`, `medium`, `high`, `critical`
- `--region`: Filter alerts to specific region
- `--category`: Filter alerts to specific category

### Running the Service

```bash
# Run once and exit
sjs-jobwatch run --once

# Run continuously
sjs-jobwatch run

# Dry run (no emails)
sjs-jobwatch run --dry-run --once

# Verbose logging
sjs-jobwatch run --once -v
```

---

## ğŸ“Š How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper    â”‚  Fetch jobs from SJS website
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Snapshot   â”‚  Save point-in-time snapshot
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Diff Engine â”‚  Compare snapshots
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Filters &   â”‚  Apply subscription filters
â”‚  Severity    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Email Rendererâ”‚  Generate HTML/text emails
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SMTP Sender  â”‚  Deliver emails
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Scraping**: HTTP request â†’ BeautifulSoup â†’ Extract `__NEXT_DATA__` script â†’ Parse JSON
2. **Storage**: Snapshot â†’ JSON file with timestamp filename
3. **Diffing**: Load two snapshots â†’ Compare by job ID â†’ Identify changes
4. **Filtering**: Apply region/category/severity filters per subscription
5. **Rendering**: Changes â†’ Jinja2 templates â†’ HTML + text emails
6. **Delivery**: SMTP â†’ Gmail â†’ Recipient

### Why Not Use Playwright?

The original project used Playwright (headless browser), but the SJS site is server-side rendered with Next.js, which embeds all job data in `<script id="__NEXT_DATA__">` tags. This means we can use simple HTTP requests + BeautifulSoup, which is:
- âœ… **Faster** (no browser overhead)
- âœ… **Lighter** (no Chromium dependencies)
- âœ… **Simpler** (fewer moving parts)
- âœ… **More reliable** (fewer things to break)

---

## ğŸ—‚ï¸ Project Structure

```
sjs-jobwatch/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ sjs_jobwatch/
â”‚       â”œâ”€â”€ core/              # Domain models and business logic
â”‚       â”‚   â”œâ”€â”€ models.py      # Pydantic models (Job, Snapshot, etc.)
â”‚       â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚       â”‚   â””â”€â”€ diff.py        # Diff engine
â”‚       â”œâ”€â”€ ingestion/         # Web scraping
â”‚       â”‚   â””â”€â”€ scraper.py     # SJS scraper implementation
â”‚       â”œâ”€â”€ storage/           # Persistence
â”‚       â”‚   â””â”€â”€ snapshots.py   # Snapshot storage
â”‚       â”œâ”€â”€ alerts/            # Email notifications
â”‚       â”‚   â”œâ”€â”€ email.py       # Email rendering and sending
â”‚       â”‚   â”œâ”€â”€ subscriptions.py  # Subscription management
â”‚       â”‚   â””â”€â”€ templates/     # Email templates
â”‚       â”‚       â”œâ”€â”€ alert_email.html
â”‚       â”‚       â””â”€â”€ alert_email.txt
â”‚       â””â”€â”€ cli/               # Command-line interface
â”‚           â””â”€â”€ main.py        # CLI entry point
â”œâ”€â”€ data/                      # Data directory (created automatically)
â”‚   â”œâ”€â”€ snapshots/            # Historical snapshots
â”‚   â”œâ”€â”€ exports/              # Exported data
â”‚   â””â”€â”€ jobwatch.log          # Application logs
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ docs/                      # Additional documentation
â”œâ”€â”€ pyproject.toml            # Project metadata and dependencies
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ .gitignore
```

---

## ğŸ§ª Development

### Running Tests

```bash
pytest
pytest -v                    # Verbose
pytest --cov=sjs_jobwatch   # With coverage
```

### Code Quality

```bash
# Format code
black src/ tests/

# Lint
ruff check src/ tests/

# Type check
mypy src/
```

### Adding Features

The codebase is designed to be extensible:

1. **New scrapers**: Subclass or extend `SJSScraper`
2. **New filters**: Add methods to `AlertSubscription`
3. **New output formats**: Add commands to CLI
4. **New notification channels**: Implement new sinks (e.g., Slack, Discord)

---

## ğŸ› Troubleshooting

### "Could not find __NEXT_DATA__ script tag"

The SJS website structure may have changed. Check the HTML source of the jobs page and update the scraper accordingly.

### "Failed to send email"

1. Verify `GMAIL_ADDRESS` and `GMAIL_APP_PASSWORD` are set
2. Check that you're using an **App Password**, not your regular password
3. Ensure Gmail SMTP is not blocked by your firewall
4. Try the test command: `sjs-jobwatch alerts test your@email.com --dry-run`

### "No snapshots found"

Run `sjs-jobwatch scrape` at least once to create initial data.

### Slow scraping

The scraper includes a 2-second delay between requests to be respectful to the server. This is intentional and configurable in `config.py`.

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests
5. Run quality checks (`black`, `ruff`, `mypy`, `pytest`)
6. Commit (`git commit -m 'Add amazing feature'`)
7. Push (`git push origin feature/amazing-feature`)
8. Open a Pull Request

---

## License

MIT License - see LICENSE file for details.

---

## ğŸ”® Roadmap

Future enhancements planned:
- [ ] Web dashboard for viewing trends
- [ ] Database backend (SQLite/PostgreSQL)
- [ ] Machine learning for job recommendations
- [ ] Multi-site support (beyond SJS)
- [ ] Slack/Discord integrations
- [ ] Job similarity detection
- [ ] Salary trend analysis
- [ ] API for integrations

---

**Happy job hunting! ğŸ¯**
